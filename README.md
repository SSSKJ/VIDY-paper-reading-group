# VIDY Paper Reading Group 2023-2024 :books:
Welcome to our bi-weekly joint reading group with Dartmouth, UIUC, VT, and Yale. To participate, please [sign up](https://docs.google.com/spreadsheets/d/1JMuGP3ZWm5-kTFGE25K-lv-XACAUIPpcwbHk5Ss65OE/edit?usp=sharing) for a role and choose a paper to present.   

<table>
  <tr>
    <td align="center">
      <img src="https://marvel-b1-cdn.bc0a.com/f00000000283318/communications.dartmouth.edu/sites/communications.prod/files/dpine_lockup.jpg" alt="Dartmouth" width="200"/>
    </td>
    <td align="center">
      <img src="https://brand.illinois.edu/wp-content/uploads/2021/09/wordmark.png" alt="UIUC" width="200"/>
    </td>
    <td align="center">
      <img src="https://vtnews.vt.edu/global_assets/images/logo-maroon.svg" alt="VT" width="200"/>
    </td>
    <td align="center">
      <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Yale_University_logo.svg/1280px-Yale_University_logo.svg.png" alt="Yale" width="200"/>
    </td>
  </tr>
</table>

In this repository, you will find the paper list and slidedecks.

----

## Timeline
|Meeting date|Theme|Topic|Paper|Slidedeck|Resources|
|-|-|-|-|-|-|
|2023/10/04|Algorithm|Generative models|[DiGress: Discrete Denoising diffusion for graph generation](https://arxiv.org/abs/2209.14734)|||
|2023/10/18|Algorithm|Transfer learning, domain adaptation|[Graph Optimal Transport for Cross-Domain Alignment](http://proceedings.mlr.press/v119/chen20e/chen20e.pdf)|||
|2023/11/01|Algorithm|Distributed algorithms|[MocoSFL: enabling cross-client collaborative self-supervised learning](https://openreview.net/forum?id=2QGJXyMNoPz)|||
|2023/11/15|Algorithm|Unlearning|[Certified Data Removal from Machine Learning Models](https://arxiv.org/pdf/1911.03030.pdf)|||
|2023/11/29|Algorithm|Symbolic reasoning and learning|[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf), [SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS](https://arxiv.org/pdf/2203.11171.pdf), [LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2205.10625.pdf), [LANGUAGE MODELS ARE MULTILINGUAL CHAIN-OF-THOUGHT REASONERS](https://arxiv.org/pdf/2210.03057.pdf)|||
|2023/12/13|Algorithm|Uncertainty quantification|[Dropout as Bayesian approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/pdf/1506.02142.pdf), [Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles](https://arxiv.org/pdf/1612.01474.pdf)|||
|2023/12/27|Applications|Drug discovery|[Geometric Latent Diffusion Models for 3D Molecule Generation](https://arxiv.org/abs/2305.01140)|||
|2024/01/10|Applications|Program synthesis|[Learning to Execute Programs with Instruction Pointer Attention Graph Neural Networks](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oavgGaMAAAAJ&sortby=pubdate&citation_for_view=oavgGaMAAAAJ:nRpfm8aw39MC)|||
|2024/01/24|Applications|3-D molecule|[SchNet: A continuous-filter convolutional neural network for modeling quantum interactions](https://arxiv.org/pdf/1706.08566.pdf), [SPHERICAL MESSAGE PASSING FOR 3D MOLECULAR GRAPHS](https://arxiv.org/pdf/2102.05013.pdf)|||
|2024/02/07|Applications|Brain network|[Brain Network Transformer](https://arxiv.org/abs/2210.06681)|||
|2024/02/21|Applications|Transportation network/spatial-temporal learning|[ROLAND: Graph Learning Framework for Dynamic Graphs](https://arxiv.org/abs/2208.07239)||||
|2024/03/06|Theory|Generalization|[UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) Chapter 2 & 3 (ERM & PAC Learning)|||
|2024/03/20|Theory|Generalization|[UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) Chapter 4 (Uniform Convergence)|||
|2024/04/03|Theory|Generalization|[UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) Chapter 6 (VC Dimension)|||
|2024/04/17|Theory|Generalization|[UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf) Chapter 26 (Rademacher Complexity)|||
|2024/05/01|Theory|Generalization|[UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)[ Chapter 30 & Stronger generalization bounds for deep nets via a compression approach](https://arxiv.org/pdf/1802.05296.pdf)|||
|2024/05/15|Theory|Generalization|[UML](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)[ Chapter 31 & A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks](https://arxiv.org/abs/1707.09564)|||


## Group Reading Roles
The group reading is organized around the different “roles” students play each week: Presenter, Challenger, Discussant, Summarizer, and Hacker. Roles define the lens through which students read the paper.

Note: Each student should sign up for at least **1 presenter, 2 challengers, and 1 summarizer** role. You can sign up as a 3rd challenger only if all papers have at least 2 challengers.

* Presenter: Create slides, deliver the paper presentation, and handle questions.

* Challenger: Prepare 1-2 slides, review the paper, and identify at least 3 strengths and 3 weaknesses.

* Discussant: Prepare 1-2 slides, propose a follow-up project made possible by the current paper's success, explore connections with other research, and raise discussion points for improvement and relevance.

* Summarizer: After the meeting, summarize the discussion in 2-3 slides, covering the paper's main message, contributions, limitations, and future directions. Also, collect all reading materials and upload them to our shared repository.
